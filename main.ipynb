{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook knowledge is built up step by step\n",
    "# The code is commented to explain the steps\n",
    "\n",
    "# Remaining tasks:\n",
    "# error handling\n",
    "# testing for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest API test\n",
    "import openai\n",
    "from project_secrets import *   # API key stored in project_secrets.py\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "response = openai.Completion.create(model=\"text-davinci-003\", prompt=\"Say this is a test\", temperature=0, max_tokens=7)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get a response from the API\n",
    "# Loop to get a range of responses via temperature\n",
    "\n",
    "def get_response(prompt):\n",
    "    for i in range(0, 11, 2):\n",
    "        temperature = i / 10\n",
    "        response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=temperature, max_tokens=7)\n",
    "        print(f\"Temperature: {temperature}.  Response: {response.choices[0].text}\")\n",
    "\n",
    "prompt=\"Say something like, 'this is only a test', but change the output\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse & print JSON response to get temperature, text, logprobs, and usage data\n",
    "import json\n",
    "\n",
    "def get_response(prompt):\n",
    "    for i in range(0, 11, 2):\n",
    "        temperature = i / 10\n",
    "        response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=temperature, max_tokens=7)\n",
    "        data = response.to_dict()\n",
    "        id = data['id']\n",
    "        text = data['choices'][0]['text'].strip()\n",
    "        logprobs = data['choices'][0]['logprobs']\n",
    "        completion_tokens = data['usage']['completion_tokens']\n",
    "        prompt_tokens = data['usage']['prompt_tokens']\n",
    "        total_tokens = data['usage']['total_tokens']\n",
    "        print(f\"Response: {text}\")\n",
    "        print(f\"\\tTemperature:{temperature} ; Logprobs:{logprobs} ; Prompt tokens:{prompt_tokens} ; Total tokens:{total_tokens} ; Completion tokens:{completion_tokens}\")\n",
    "\n",
    "prompt=\"Say something like, 'this is only a test', but change the output\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   id  temperature                    text  \\\n",
      "0  cmpl-79FwdgPoaqnWAM0jNn3nSG8YizUqs          0.0  This is merely a trial   \n",
      "1  cmpl-79Fwe4LALvg4OLPAyhyfBN96bGL1h          0.2  This is merely a trial   \n",
      "2  cmpl-79FwfZmGvlDnduiG68QaO98BSM7zK          0.4  This is merely a trial   \n",
      "3  cmpl-79Fwg8UPoQqE7lgiO4vmtMGbgOdKS          0.6  This is merely a trial   \n",
      "4  cmpl-79Fwgajz5EjujArH9afKVTn49vEKS          0.8  This is merely a trial   \n",
      "5  cmpl-79Fwh7fNRrejRy40JPbrcR9Rj4fAG          1.0  This is merely a trial   \n",
      "\n",
      "  logprobs  completion_tokens  prompt_tokens  total_tokens  \n",
      "0     None                  7              9            16  \n",
      "1     None                  7              9            16  \n",
      "2     None                  7              9            16  \n",
      "3     None                  7              9            16  \n",
      "4     None                  7              9            16  \n",
      "5     None                  7              9            16  \n"
     ]
    }
   ],
   "source": [
    "# Store the data in a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "def get_response(prompt):\n",
    "    for i in range(0, 11, 2):\n",
    "       temperature = i / 10\n",
    "       response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=temperature, max_tokens=7)\n",
    "       new_temp = {\"temp\": temperature}\n",
    "       response.update(new_temp)\n",
    "       data.append(response)\n",
    "\n",
    "prompt = \"Express 'this is only a test' differently\"\n",
    "get_response(prompt)\n",
    "\n",
    "normalized = pd.json_normalize(data)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['id'] = normalized['id']\n",
    "df['temperature'] = normalized['temp']\n",
    "df['text'] = normalized['choices'][0][0]['text'].strip()\n",
    "df['logprobs'] = normalized['choices'][0][0]['logprobs']\n",
    "df['completion_tokens'] = normalized['usage.completion_tokens']\n",
    "df['prompt_tokens'] = normalized['usage.prompt_tokens']\n",
    "df['total_tokens'] = normalized['usage.total_tokens']\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
