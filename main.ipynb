{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook knowledge is built up step by step\n",
    "# The code is commented to explain the steps\n",
    "\n",
    "# Remaining tasks:\n",
    "# error handling\n",
    "# testing for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest API test\n",
    "import openai\n",
    "from project_secrets import *   # API key stored in project_secrets.py\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "response = openai.Completion.create(model=\"text-davinci-003\", prompt=\"Say this is a test\", temperature=0, max_tokens=7)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get a response from the API\n",
    "# Loop to get a range of responses via temperature\n",
    "\n",
    "def get_response(prompt):\n",
    "    for i in range(0, 11, 2):\n",
    "        temperature = i / 10\n",
    "        response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=temperature, max_tokens=7)\n",
    "        print(f\"Temperature: {temperature}.  Response: {response.choices[0].text}\")\n",
    "\n",
    "prompt=\"Say something like, 'this is only a test', but change the output\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse & print JSON response to get temperature, text, logprobs, and usage data\n",
    "import json\n",
    "\n",
    "def get_response(prompt):\n",
    "    for i in range(0, 11, 2):\n",
    "        temperature = i / 10\n",
    "        response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=temperature, max_tokens=7)\n",
    "        data = response.to_dict()\n",
    "        id = data['id']\n",
    "        text = data['choices'][0]['text'].strip()\n",
    "        logprobs = data['choices'][0]['logprobs']\n",
    "        completion_tokens = data['usage']['completion_tokens']\n",
    "        prompt_tokens = data['usage']['prompt_tokens']\n",
    "        total_tokens = data['usage']['total_tokens']\n",
    "        print(f\"Response: {text}\")\n",
    "        print(f\"\\tTemperature:{temperature} ; Logprobs:{logprobs} ; Prompt tokens:{prompt_tokens} ; Total tokens:{total_tokens} ; Completion tokens:{completion_tokens}\")\n",
    "\n",
    "prompt=\"Say something like, 'this is only a test', but change the output\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    id  temperature  \\\n",
      "0   cmpl-79FuAr2VDSXihehkkzvGPNsnL78Hy          0.0   \n",
      "1   cmpl-79FuB6iAv3HF5oGu0XlpNOS23KvwR          0.2   \n",
      "2   cmpl-79FuCmkXi1nM2vd7Tg5DnY5VVPPEm          0.4   \n",
      "3   cmpl-79FuD3mOEKdYf6Rl0uRKvUMtB6qKc          0.6   \n",
      "4   cmpl-79FuEOfiMGquUUb7lSoC8Kad6Xmdz          0.8   \n",
      "5   cmpl-79FuEuG6TYeP9ZZ6e7xEsg6yjIGP9          1.0   \n",
      "6   cmpl-79FuFRTI1oLPWRYheYuqWUDF7D06R          1.2   \n",
      "7   cmpl-79FuHQpnTIFSwNDLtS0cWNiRLDwm8          1.4   \n",
      "8   cmpl-79FuHDsmTZTM0hcqqyHll3fI9cmx0          1.6   \n",
      "9   cmpl-79FuIeZwnGom0oDIuub7KgS5rlwgA          1.8   \n",
      "10  cmpl-79FuJLbgnkR389TYEfhP54II1EdPk          2.0   \n",
      "\n",
      "                           text logprobs  completion_tokens  prompt_tokens  \\\n",
      "0   This is merely a trial run.     None                  9              9   \n",
      "1   This is merely a trial run.     None                  9              9   \n",
      "2   This is merely a trial run.     None                  9              9   \n",
      "3   This is merely a trial run.     None                  9              9   \n",
      "4   This is merely a trial run.     None                  9              9   \n",
      "5   This is merely a trial run.     None                  9              9   \n",
      "6   This is merely a trial run.     None                  9              9   \n",
      "7   This is merely a trial run.     None                  9              9   \n",
      "8   This is merely a trial run.     None                  9              9   \n",
      "9   This is merely a trial run.     None                  8              9   \n",
      "10  This is merely a trial run.     None                  9              9   \n",
      "\n",
      "    total_tokens  \n",
      "0             18  \n",
      "1             18  \n",
      "2             18  \n",
      "3             18  \n",
      "4             18  \n",
      "5             18  \n",
      "6             18  \n",
      "7             18  \n",
      "8             18  \n",
      "9             17  \n",
      "10            18  \n"
     ]
    }
   ],
   "source": [
    "# Store the data in a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "def get_response(prompt):\n",
    "    for i in range(0, 21, 2):\n",
    "       temperature = i / 10\n",
    "       response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=temperature, max_tokens=9)\n",
    "       new_temp = {\"temp\": temperature}\n",
    "       response.update(new_temp)\n",
    "       data.append(response)\n",
    "\n",
    "prompt = \"Express 'this is only a test' differently\"\n",
    "get_response(prompt)\n",
    "\n",
    "normalized = pd.json_normalize(data)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['id'] = normalized['id']\n",
    "df['temperature'] = normalized['temp']\n",
    "df['text'] = normalized['choices'][0][0]['text'].strip()\n",
    "df['logprobs'] = normalized['choices'][0][0]['logprobs']\n",
    "df['completion_tokens'] = normalized['usage.completion_tokens']\n",
    "df['prompt_tokens'] = normalized['usage.prompt_tokens']\n",
    "df['total_tokens'] = normalized['usage.total_tokens']\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
